{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d235553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65532 entries, 0 to 65531\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Source Port           65532 non-null  int64 \n",
      " 1   Destination Port      65532 non-null  int64 \n",
      " 2   NAT Source Port       65532 non-null  int64 \n",
      " 3   NAT Destination Port  65532 non-null  int64 \n",
      " 4   Action                65532 non-null  object\n",
      " 5   Bytes                 65532 non-null  int64 \n",
      " 6   Bytes Sent            65532 non-null  int64 \n",
      " 7   Bytes Received        65532 non-null  int64 \n",
      " 8   Packets               65532 non-null  int64 \n",
      " 9   Elapsed Time (sec)    65532 non-null  int64 \n",
      " 10  pkts_sent             65532 non-null  int64 \n",
      " 11  pkts_received         65532 non-null  int64 \n",
      "dtypes: int64(11), object(1)\n",
      "memory usage: 6.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "title_font = {'family': 'serif', 'color': 'darkred', 'weight': 'bold', 'size': 18}\n",
    "label_font = {'family': 'Arial', 'weight': 'normal', 'size': 16}\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('log2.csv')\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7670afa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source Port  Destination Port  NAT Source Port  NAT Destination Port  \\\n",
      "0        57222                53            54587                    53   \n",
      "1        56258              3389            56258                  3389   \n",
      "2         6881             50321            43265                 50321   \n",
      "3        50553              3389            50553                  3389   \n",
      "4        50002               443            45848                   443   \n",
      "\n",
      "  Action  Bytes  Bytes Sent  Bytes Received  Packets  Elapsed Time (sec)  \\\n",
      "0  allow    177          94              83        2                  30   \n",
      "1  allow   4768        1600            3168       19                  17   \n",
      "2  allow    238         118             120        2                1199   \n",
      "3  allow   3327        1438            1889       15                  17   \n",
      "4  allow  25358        6778           18580       31                  16   \n",
      "\n",
      "   pkts_sent  pkts_received  \n",
      "0          1              1  \n",
      "1         10              9  \n",
      "2          1              1  \n",
      "3          8              7  \n",
      "4         13             18  \n"
     ]
    }
   ],
   "source": [
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0237ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57170 entries, 0 to 65530\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Source Port           57170 non-null  int64 \n",
      " 1   Destination Port      57170 non-null  int64 \n",
      " 2   NAT Source Port       57170 non-null  int64 \n",
      " 3   NAT Destination Port  57170 non-null  int64 \n",
      " 4   Action                57170 non-null  object\n",
      " 5   Bytes                 57170 non-null  int64 \n",
      " 6   Bytes Sent            57170 non-null  int64 \n",
      " 7   Bytes Received        57170 non-null  int64 \n",
      " 8   Packets               57170 non-null  int64 \n",
      " 9   Elapsed Time (sec)    57170 non-null  int64 \n",
      " 10  pkts_sent             57170 non-null  int64 \n",
      " 11  pkts_received         57170 non-null  int64 \n",
      "dtypes: int64(11), object(1)\n",
      "memory usage: 5.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd10c5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>NAT Source Port</th>\n",
       "      <th>NAT Destination Port</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Bytes Sent</th>\n",
       "      <th>Bytes Received</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Elapsed Time (sec)</th>\n",
       "      <th>pkts_sent</th>\n",
       "      <th>pkts_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>57170.000000</td>\n",
       "      <td>57170.000000</td>\n",
       "      <td>57170.000000</td>\n",
       "      <td>57170.000000</td>\n",
       "      <td>5.717000e+04</td>\n",
       "      <td>5.717000e+04</td>\n",
       "      <td>5.717000e+04</td>\n",
       "      <td>5.717000e+04</td>\n",
       "      <td>57170.000000</td>\n",
       "      <td>57170.000000</td>\n",
       "      <td>57170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50532.499738</td>\n",
       "      <td>8052.147035</td>\n",
       "      <td>22048.739549</td>\n",
       "      <td>3054.123491</td>\n",
       "      <td>1.113147e+05</td>\n",
       "      <td>2.564701e+04</td>\n",
       "      <td>8.566766e+04</td>\n",
       "      <td>1.177065e+02</td>\n",
       "      <td>75.116547</td>\n",
       "      <td>47.279255</td>\n",
       "      <td>70.427200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13880.680957</td>\n",
       "      <td>16513.145167</td>\n",
       "      <td>22141.986286</td>\n",
       "      <td>10363.545911</td>\n",
       "      <td>6.015189e+06</td>\n",
       "      <td>4.098545e+06</td>\n",
       "      <td>2.637029e+06</td>\n",
       "      <td>5.495436e+03</td>\n",
       "      <td>322.519323</td>\n",
       "      <td>3446.210063</td>\n",
       "      <td>2380.254144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49450.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54013.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>16362.500000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.930000e+02</td>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>9.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58574.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>41883.750000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>1.139000e+03</td>\n",
       "      <td>5.080000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65534.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>1.269359e+09</td>\n",
       "      <td>9.484772e+08</td>\n",
       "      <td>3.208818e+08</td>\n",
       "      <td>1.036116e+06</td>\n",
       "      <td>10824.000000</td>\n",
       "      <td>747520.000000</td>\n",
       "      <td>327208.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source Port  Destination Port  NAT Source Port  NAT Destination Port  \\\n",
       "count  57170.000000      57170.000000     57170.000000          57170.000000   \n",
       "mean   50532.499738       8052.147035     22048.739549           3054.123491   \n",
       "std    13880.680957      16513.145167     22141.986286          10363.545911   \n",
       "min        0.000000          0.000000         0.000000              0.000000   \n",
       "25%    49450.000000         53.000000         0.000000              0.000000   \n",
       "50%    54013.000000        443.000000     16362.500000             53.000000   \n",
       "75%    58574.000000        445.000000     41883.750000            443.000000   \n",
       "max    65534.000000      65535.000000     65535.000000          65535.000000   \n",
       "\n",
       "              Bytes    Bytes Sent  Bytes Received       Packets  \\\n",
       "count  5.717000e+04  5.717000e+04    5.717000e+04  5.717000e+04   \n",
       "mean   1.113147e+05  2.564701e+04    8.566766e+04  1.177065e+02   \n",
       "std    6.015189e+06  4.098545e+06    2.637029e+06  5.495436e+03   \n",
       "min    6.000000e+01  6.000000e+01    0.000000e+00  1.000000e+00   \n",
       "25%    7.000000e+01  7.000000e+01    0.000000e+00  1.000000e+00   \n",
       "50%    1.930000e+02  9.400000e+01    9.000000e+01  2.000000e+00   \n",
       "75%    1.139000e+03  5.080000e+02    6.690000e+02  1.000000e+01   \n",
       "max    1.269359e+09  9.484772e+08    3.208818e+08  1.036116e+06   \n",
       "\n",
       "       Elapsed Time (sec)      pkts_sent  pkts_received  \n",
       "count        57170.000000   57170.000000   57170.000000  \n",
       "mean            75.116547      47.279255      70.427200  \n",
       "std            322.519323    3446.210063    2380.254144  \n",
       "min              0.000000       1.000000       0.000000  \n",
       "25%              0.000000       1.000000       0.000000  \n",
       "50%             26.000000       1.000000       1.000000  \n",
       "75%             31.000000       5.000000       4.000000  \n",
       "max          10824.000000  747520.000000  327208.000000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd601d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ff3bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Source Port  Destination Port  NAT Source Port  NAT Destination Port  \\\n",
      "0            57222                53            54587                    53   \n",
      "1            56258              3389            56258                  3389   \n",
      "2             6881             50321            43265                 50321   \n",
      "3            50553              3389            50553                  3389   \n",
      "4            50002               443            45848                   443   \n",
      "...            ...               ...              ...                   ...   \n",
      "65526        51710             43069            65147                 43069   \n",
      "65527        63691                80            13237                    80   \n",
      "65528        50964                80            13485                    80   \n",
      "65529        54871               445                0                     0   \n",
      "65530        54870               445                0                     0   \n",
      "\n",
      "         Bytes  Bytes Sent  Bytes Received  Packets  Elapsed Time (sec)  \\\n",
      "0          177          94              83        2                  30   \n",
      "1         4768        1600            3168       19                  17   \n",
      "2          238         118             120        2                1199   \n",
      "3         3327        1438            1889       15                  17   \n",
      "4        25358        6778           18580       31                  16   \n",
      "...        ...         ...             ...      ...                 ...   \n",
      "65526       70          70               0        2                   8   \n",
      "65527      314         192             122        6                  15   \n",
      "65528  4680740       67312         4613428     4675                  77   \n",
      "65529       70          70               0        1                   0   \n",
      "65530       70          70               0        1                   0   \n",
      "\n",
      "       pkts_sent  pkts_received  \n",
      "0              1              1  \n",
      "1             10              9  \n",
      "2              1              1  \n",
      "3              8              7  \n",
      "4             13             18  \n",
      "...          ...            ...  \n",
      "65526          2              0  \n",
      "65527          4              2  \n",
      "65528        985           3690  \n",
      "65529          1              0  \n",
      "65530          1              0  \n",
      "\n",
      "[57170 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "y = df['Action'].values\n",
    "y = y.reshape(-1,1)\n",
    "x_data = df.drop(['Action'],axis = 1)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46da3b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    628870.000000\n",
       "mean          0.116792\n",
       "std           0.273638\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000003\n",
       "75%           0.006760\n",
       "max           1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NORMALIZATION\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create an instance of MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "x_normalized = min_max_scaler.fit_transform(x_data)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "x = pd.DataFrame(x_normalized, columns=x_data.columns)\n",
    "\n",
    "# Check the statistics of the normalized data\n",
    "pd.Series(x.values.flatten()).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eddff0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>NAT Source Port</th>\n",
       "      <th>NAT Destination Port</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Bytes Sent</th>\n",
       "      <th>Bytes Received</th>\n",
       "      <th>Packets</th>\n",
       "      <th>Elapsed Time (sec)</th>\n",
       "      <th>pkts_sent</th>\n",
       "      <th>pkts_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.873165</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.832944</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>9.217251e-08</td>\n",
       "      <td>3.584694e-08</td>\n",
       "      <td>2.586622e-07</td>\n",
       "      <td>9.651438e-07</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.858455</td>\n",
       "      <td>0.051713</td>\n",
       "      <td>0.858442</td>\n",
       "      <td>0.051713</td>\n",
       "      <td>3.708959e-06</td>\n",
       "      <td>1.623655e-06</td>\n",
       "      <td>9.872794e-06</td>\n",
       "      <td>1.737259e-05</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104999</td>\n",
       "      <td>0.767849</td>\n",
       "      <td>0.660182</td>\n",
       "      <td>0.767849</td>\n",
       "      <td>1.402283e-07</td>\n",
       "      <td>6.115066e-08</td>\n",
       "      <td>3.739695e-07</td>\n",
       "      <td>9.651438e-07</td>\n",
       "      <td>0.110772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.771401</td>\n",
       "      <td>0.051713</td>\n",
       "      <td>0.771389</td>\n",
       "      <td>0.051713</td>\n",
       "      <td>2.573740e-06</td>\n",
       "      <td>1.452855e-06</td>\n",
       "      <td>5.886903e-06</td>\n",
       "      <td>1.351201e-05</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.762993</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.699596</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>1.992974e-05</td>\n",
       "      <td>7.082933e-06</td>\n",
       "      <td>5.790294e-05</td>\n",
       "      <td>2.895431e-05</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source Port  Destination Port  NAT Source Port  NAT Destination Port  \\\n",
       "0     0.873165          0.000809         0.832944              0.000809   \n",
       "1     0.858455          0.051713         0.858442              0.051713   \n",
       "2     0.104999          0.767849         0.660182              0.767849   \n",
       "3     0.771401          0.051713         0.771389              0.051713   \n",
       "4     0.762993          0.006760         0.699596              0.006760   \n",
       "\n",
       "          Bytes    Bytes Sent  Bytes Received       Packets  \\\n",
       "0  9.217251e-08  3.584694e-08    2.586622e-07  9.651438e-07   \n",
       "1  3.708959e-06  1.623655e-06    9.872794e-06  1.737259e-05   \n",
       "2  1.402283e-07  6.115066e-08    3.739695e-07  9.651438e-07   \n",
       "3  2.573740e-06  1.452855e-06    5.886903e-06  1.351201e-05   \n",
       "4  1.992974e-05  7.082933e-06    5.790294e-05  2.895431e-05   \n",
       "\n",
       "   Elapsed Time (sec)  pkts_sent  pkts_received  \n",
       "0            0.002772   0.000000       0.000003  \n",
       "1            0.001571   0.000012       0.000028  \n",
       "2            0.110772   0.000000       0.000003  \n",
       "3            0.001571   0.000009       0.000021  \n",
       "4            0.001478   0.000016       0.000055  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93bd513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c26ed4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "encoded_Y = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "\n",
    "encoded_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13ebb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, encoded_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c1bdbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_elements</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allow</td>\n",
       "      <td>30009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deny</td>\n",
       "      <td>6427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drop</td>\n",
       "      <td>9254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reset-both</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_elements  count\n",
       "0           allow  30009\n",
       "1            deny   6427\n",
       "2            drop   9254\n",
       "3      reset-both     46"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_transformed_array_trainY = encoder.inverse_transform(y_train)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(re_transformed_array_trainY, return_counts=True)\n",
    "unique_elements_and_counts_trainY = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)\n",
    "unique_elements_and_counts_trainY.columns = ['unique_elements', 'count']\n",
    "\n",
    "unique_elements_and_counts_trainY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "608cd108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_elements</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allow</td>\n",
       "      <td>7430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deny</td>\n",
       "      <td>1615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drop</td>\n",
       "      <td>2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reset-both</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_elements count\n",
       "0           allow  7430\n",
       "1            deny  1615\n",
       "2            drop  2381\n",
       "3      reset-both     8"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_transformed_array_testY = encoder.inverse_transform(y_test)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(re_transformed_array_testY, return_counts=True)\n",
    "unique_elements_and_counts_testY = pd.DataFrame(np.asarray((unique_elements, counts_elements)).T)\n",
    "unique_elements_and_counts_testY.columns = ['unique_elements', 'count']\n",
    "\n",
    "unique_elements_and_counts_testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dbd7264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allow', 'deny', 'drop', 'reset-both']\n",
      "['allow', 'deny', 'drop', 'reset-both']\n"
     ]
    }
   ],
   "source": [
    "list_trainY = unique_elements_and_counts_trainY['unique_elements'].to_list()\n",
    "\n",
    "list_testY = unique_elements_and_counts_testY['unique_elements'].to_list()\n",
    "\n",
    "print(list_trainY)\n",
    "\n",
    "print(list_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c2c15e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: 11\n",
      "Batch Size: 20\n",
      "\n",
      "Steps per Epoch: 2286\n",
      "\n",
      "Test Steps: 571\n",
      "\n",
      "Number of Epochs: 100\n",
      "\n",
      "Number of Classes: 4\n"
     ]
    }
   ],
   "source": [
    "trainX = X_train\n",
    "trainY = y_train\n",
    "\n",
    "testX = X_test\n",
    "testY = y_test\n",
    "input_shape = trainX.shape[1]\n",
    "\n",
    "n_batch_size = 20\n",
    "\n",
    "n_steps_per_epoch = int(trainX.shape[0] / n_batch_size)\n",
    "\n",
    "n_test_steps = int(testX.shape[0] / n_batch_size)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "num_classes = trainY.shape[1]\n",
    "\n",
    "print('Input Shape: ' + str(input_shape))\n",
    "print('Batch Size: ' + str(n_batch_size))\n",
    "print()\n",
    "print('Steps per Epoch: ' + str(n_steps_per_epoch))\n",
    "print()\n",
    "\n",
    "print('Test Steps: ' + str(n_test_steps))\n",
    "print()\n",
    "print('Number of Epochs: ' + str(n_epochs))\n",
    "print()\n",
    "print('Number of Classes: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d90914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(input_shape,)))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d6ee095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 20)                240       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 744 (2.91 KB)\n",
      "Trainable params: 744 (2.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "16a937db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2286/2286 [==============================] - 2s 811us/step - loss: 0.2146 - accuracy: 0.9302\n",
      "Epoch 2/100\n",
      "2286/2286 [==============================] - 2s 804us/step - loss: 0.0802 - accuracy: 0.9810\n",
      "Epoch 3/100\n",
      "2286/2286 [==============================] - 2s 857us/step - loss: 0.0680 - accuracy: 0.9841\n",
      "Epoch 4/100\n",
      "2286/2286 [==============================] - 2s 830us/step - loss: 0.0606 - accuracy: 0.9857\n",
      "Epoch 5/100\n",
      "2286/2286 [==============================] - 2s 798us/step - loss: 0.0533 - accuracy: 0.9867\n",
      "Epoch 6/100\n",
      "2286/2286 [==============================] - 2s 842us/step - loss: 0.0459 - accuracy: 0.9886\n",
      "Epoch 7/100\n",
      "2286/2286 [==============================] - 2s 963us/step - loss: 0.0393 - accuracy: 0.9913\n",
      "Epoch 8/100\n",
      "2286/2286 [==============================] - 2s 923us/step - loss: 0.0337 - accuracy: 0.9922\n",
      "Epoch 9/100\n",
      "2286/2286 [==============================] - 2s 828us/step - loss: 0.0292 - accuracy: 0.9928\n",
      "Epoch 10/100\n",
      "2286/2286 [==============================] - 2s 907us/step - loss: 0.0258 - accuracy: 0.9939\n",
      "Epoch 11/100\n",
      "2286/2286 [==============================] - 2s 745us/step - loss: 0.0233 - accuracy: 0.9951\n",
      "Epoch 12/100\n",
      "2286/2286 [==============================] - 2s 740us/step - loss: 0.0205 - accuracy: 0.9959\n",
      "Epoch 13/100\n",
      "2286/2286 [==============================] - 2s 766us/step - loss: 0.0197 - accuracy: 0.9960\n",
      "Epoch 14/100\n",
      "2286/2286 [==============================] - 2s 746us/step - loss: 0.0185 - accuracy: 0.9965\n",
      "Epoch 15/100\n",
      "2286/2286 [==============================] - 2s 781us/step - loss: 0.0175 - accuracy: 0.9967\n",
      "Epoch 16/100\n",
      "2286/2286 [==============================] - 2s 800us/step - loss: 0.0169 - accuracy: 0.9969\n",
      "Epoch 17/100\n",
      "2286/2286 [==============================] - 2s 847us/step - loss: 0.0164 - accuracy: 0.9970\n",
      "Epoch 18/100\n",
      "2286/2286 [==============================] - 1s 572us/step - loss: 0.0158 - accuracy: 0.9971\n",
      "Epoch 19/100\n",
      "2286/2286 [==============================] - 1s 550us/step - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 20/100\n",
      "2286/2286 [==============================] - 1s 557us/step - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 21/100\n",
      "2286/2286 [==============================] - 1s 542us/step - loss: 0.0152 - accuracy: 0.9973\n",
      "Epoch 22/100\n",
      "2286/2286 [==============================] - 2s 795us/step - loss: 0.0150 - accuracy: 0.9973\n",
      "Epoch 23/100\n",
      "2286/2286 [==============================] - 2s 718us/step - loss: 0.0149 - accuracy: 0.9974\n",
      "Epoch 24/100\n",
      "2286/2286 [==============================] - 2s 710us/step - loss: 0.0147 - accuracy: 0.9973\n",
      "Epoch 25/100\n",
      "2286/2286 [==============================] - 1s 547us/step - loss: 0.0146 - accuracy: 0.9974\n",
      "Epoch 26/100\n",
      "2286/2286 [==============================] - 1s 526us/step - loss: 0.0139 - accuracy: 0.9975\n",
      "Epoch 27/100\n",
      "2286/2286 [==============================] - 1s 591us/step - loss: 0.0146 - accuracy: 0.9974\n",
      "Epoch 28/100\n",
      "2286/2286 [==============================] - 2s 725us/step - loss: 0.0141 - accuracy: 0.9975\n",
      "Epoch 29/100\n",
      "2286/2286 [==============================] - 1s 577us/step - loss: 0.0146 - accuracy: 0.9974\n",
      "Epoch 30/100\n",
      "2286/2286 [==============================] - 1s 581us/step - loss: 0.0140 - accuracy: 0.9974\n",
      "Epoch 31/100\n",
      "2286/2286 [==============================] - 2s 746us/step - loss: 0.0142 - accuracy: 0.9974\n",
      "Epoch 32/100\n",
      "2286/2286 [==============================] - 1s 645us/step - loss: 0.0141 - accuracy: 0.9974\n",
      "Epoch 33/100\n",
      "2286/2286 [==============================] - 1s 630us/step - loss: 0.0136 - accuracy: 0.9975\n",
      "Epoch 34/100\n",
      "2286/2286 [==============================] - 1s 610us/step - loss: 0.0140 - accuracy: 0.9975\n",
      "Epoch 35/100\n",
      "2286/2286 [==============================] - 1s 600us/step - loss: 0.0139 - accuracy: 0.9973\n",
      "Epoch 36/100\n",
      "2286/2286 [==============================] - 1s 537us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "2286/2286 [==============================] - 1s 550us/step - loss: 0.0136 - accuracy: 0.9976\n",
      "Epoch 38/100\n",
      "2286/2286 [==============================] - 1s 565us/step - loss: 0.0138 - accuracy: 0.9974\n",
      "Epoch 39/100\n",
      "2286/2286 [==============================] - 2s 822us/step - loss: 0.0134 - accuracy: 0.9974\n",
      "Epoch 40/100\n",
      "2286/2286 [==============================] - 1s 609us/step - loss: 0.0135 - accuracy: 0.9974\n",
      "Epoch 41/100\n",
      "2286/2286 [==============================] - 1s 568us/step - loss: 0.0134 - accuracy: 0.9974\n",
      "Epoch 42/100\n",
      "2286/2286 [==============================] - 1s 571us/step - loss: 0.0135 - accuracy: 0.9975\n",
      "Epoch 43/100\n",
      "2286/2286 [==============================] - 1s 543us/step - loss: 0.0134 - accuracy: 0.9975\n",
      "Epoch 44/100\n",
      "2286/2286 [==============================] - 2s 664us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 45/100\n",
      "2286/2286 [==============================] - 2s 668us/step - loss: 0.0131 - accuracy: 0.9976\n",
      "Epoch 46/100\n",
      "2286/2286 [==============================] - 2s 733us/step - loss: 0.0130 - accuracy: 0.9976\n",
      "Epoch 47/100\n",
      "2286/2286 [==============================] - 1s 583us/step - loss: 0.0136 - accuracy: 0.9976\n",
      "Epoch 48/100\n",
      "2286/2286 [==============================] - 1s 598us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 49/100\n",
      "2286/2286 [==============================] - 1s 636us/step - loss: 0.0130 - accuracy: 0.9976\n",
      "Epoch 50/100\n",
      "2286/2286 [==============================] - 2s 766us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 51/100\n",
      "2286/2286 [==============================] - 1s 585us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 52/100\n",
      "2286/2286 [==============================] - 1s 613us/step - loss: 0.0130 - accuracy: 0.9977\n",
      "Epoch 53/100\n",
      "2286/2286 [==============================] - 1s 571us/step - loss: 0.0129 - accuracy: 0.9976\n",
      "Epoch 54/100\n",
      "2286/2286 [==============================] - 2s 792us/step - loss: 0.0128 - accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "2286/2286 [==============================] - 2s 661us/step - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "2286/2286 [==============================] - 1s 591us/step - loss: 0.0131 - accuracy: 0.9976\n",
      "Epoch 57/100\n",
      "2286/2286 [==============================] - 1s 530us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 58/100\n",
      "2286/2286 [==============================] - 1s 541us/step - loss: 0.0127 - accuracy: 0.9976\n",
      "Epoch 59/100\n",
      "2286/2286 [==============================] - 2s 675us/step - loss: 0.0125 - accuracy: 0.9977\n",
      "Epoch 60/100\n",
      "2286/2286 [==============================] - 1s 598us/step - loss: 0.0126 - accuracy: 0.9976\n",
      "Epoch 61/100\n",
      "2286/2286 [==============================] - 1s 649us/step - loss: 0.0131 - accuracy: 0.9975\n",
      "Epoch 62/100\n",
      "2286/2286 [==============================] - 1s 630us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 63/100\n",
      "2286/2286 [==============================] - 1s 562us/step - loss: 0.0124 - accuracy: 0.9978\n",
      "Epoch 64/100\n",
      "2286/2286 [==============================] - 1s 544us/step - loss: 0.0125 - accuracy: 0.9977\n",
      "Epoch 65/100\n",
      "2286/2286 [==============================] - 2s 758us/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 66/100\n",
      "2286/2286 [==============================] - 2s 913us/step - loss: 0.0126 - accuracy: 0.9976\n",
      "Epoch 67/100\n",
      "2286/2286 [==============================] - 2s 912us/step - loss: 0.0127 - accuracy: 0.9977\n",
      "Epoch 68/100\n",
      "2286/2286 [==============================] - 2s 890us/step - loss: 0.0128 - accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "2286/2286 [==============================] - 1s 555us/step - loss: 0.0128 - accuracy: 0.9975\n",
      "Epoch 70/100\n",
      "2286/2286 [==============================] - 1s 557us/step - loss: 0.0123 - accuracy: 0.9977\n",
      "Epoch 71/100\n",
      "2286/2286 [==============================] - 2s 669us/step - loss: 0.0127 - accuracy: 0.9976\n",
      "Epoch 72/100\n",
      "2286/2286 [==============================] - 2s 892us/step - loss: 0.0127 - accuracy: 0.9976\n",
      "Epoch 73/100\n",
      "2286/2286 [==============================] - 1s 636us/step - loss: 0.0130 - accuracy: 0.9975\n",
      "Epoch 74/100\n",
      "2286/2286 [==============================] - 1s 608us/step - loss: 0.0128 - accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "2286/2286 [==============================] - 1s 643us/step - loss: 0.0122 - accuracy: 0.9977\n",
      "Epoch 76/100\n",
      "2286/2286 [==============================] - 1s 615us/step - loss: 0.0126 - accuracy: 0.9978\n",
      "Epoch 77/100\n",
      "2286/2286 [==============================] - 2s 815us/step - loss: 0.0124 - accuracy: 0.9976\n",
      "Epoch 78/100\n",
      "2286/2286 [==============================] - 1s 651us/step - loss: 0.0126 - accuracy: 0.9976\n",
      "Epoch 79/100\n",
      "2286/2286 [==============================] - 1s 592us/step - loss: 0.0130 - accuracy: 0.9976\n",
      "Epoch 80/100\n",
      "2286/2286 [==============================] - 2s 674us/step - loss: 0.0126 - accuracy: 0.9976\n",
      "Epoch 81/100\n",
      "2286/2286 [==============================] - 2s 1ms/step - loss: 0.0126 - accuracy: 0.9977\n",
      "Epoch 82/100\n",
      "2286/2286 [==============================] - 2s 976us/step - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 83/100\n",
      "2286/2286 [==============================] - 3s 1ms/step - loss: 0.0125 - accuracy: 0.9975\n",
      "Epoch 84/100\n",
      "2286/2286 [==============================] - 1s 645us/step - loss: 0.0127 - accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "2286/2286 [==============================] - 2s 849us/step - loss: 0.0120 - accuracy: 0.9978\n",
      "Epoch 86/100\n",
      "2286/2286 [==============================] - 1s 543us/step - loss: 0.0131 - accuracy: 0.9976\n",
      "Epoch 87/100\n",
      "2286/2286 [==============================] - 1s 536us/step - loss: 0.0129 - accuracy: 0.9977\n",
      "Epoch 88/100\n",
      "2286/2286 [==============================] - 1s 538us/step - loss: 0.0126 - accuracy: 0.9975\n",
      "Epoch 89/100\n",
      "2286/2286 [==============================] - 1s 557us/step - loss: 0.0123 - accuracy: 0.9977\n",
      "Epoch 90/100\n",
      "2286/2286 [==============================] - 1s 564us/step - loss: 0.0126 - accuracy: 0.9976\n",
      "Epoch 91/100\n",
      "2286/2286 [==============================] - 2s 766us/step - loss: 0.0121 - accuracy: 0.9977\n",
      "Epoch 92/100\n",
      "2286/2286 [==============================] - 1s 526us/step - loss: 0.0125 - accuracy: 0.9976\n",
      "Epoch 93/100\n",
      "2286/2286 [==============================] - 1s 532us/step - loss: 0.0125 - accuracy: 0.9977\n",
      "Epoch 94/100\n",
      "2286/2286 [==============================] - 1s 543us/step - loss: 0.0128 - accuracy: 0.9975\n",
      "Epoch 95/100\n",
      "2286/2286 [==============================] - 1s 536us/step - loss: 0.0120 - accuracy: 0.9978\n",
      "Epoch 96/100\n",
      "2286/2286 [==============================] - 1s 563us/step - loss: 0.0120 - accuracy: 0.9977\n",
      "Epoch 97/100\n",
      "2286/2286 [==============================] - 1s 577us/step - loss: 0.0127 - accuracy: 0.9976\n",
      "Epoch 98/100\n",
      "2286/2286 [==============================] - 1s 528us/step - loss: 0.0123 - accuracy: 0.9977\n",
      "Epoch 99/100\n",
      "2286/2286 [==============================] - 1s 534us/step - loss: 0.0125 - accuracy: 0.9976\n",
      "Epoch 100/100\n",
      "2286/2286 [==============================] - 1s 531us/step - loss: 0.0117 - accuracy: 0.9977\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    steps_per_epoch=n_steps_per_epoch,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4cca4bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 412us/step\n",
      "Accuracy: 0.9979009970264124\n",
      "Precision: 0.7471717863734754\n",
      "Recall: 0.7481289767447674\n",
      "F1 Score: 0.7476496546204987\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_pred_back = encoder.inverse_transform(np.eye(num_classes)[y_pred_classes])\n",
    "\n",
    "\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "y_test_back = encoder.inverse_transform(np.eye(num_classes)[y_test_classes])\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy_dnn_all = accuracy_score(y_test_back, y_pred_back)\n",
    "precision_dnn_all = precision_score(y_test_back, y_pred_back, average='macro')\n",
    "recall_dnn_all = recall_score(y_test_back, y_pred_back, average='macro')\n",
    "f1_dnn_all = f1_score(y_test_back, y_pred_back, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy_dnn_all)\n",
    "print(\"Precision:\", precision_dnn_all)\n",
    "print(\"Recall:\", recall_dnn_all)\n",
    "print(\"F1 Score:\", f1_dnn_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "584073fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: 4\n",
      "Batch Size: 20\n",
      "\n",
      "Steps per Epoch: 2286\n",
      "\n",
      "Test Steps: 571\n",
      "\n",
      "Number of Epochs: 100\n",
      "\n",
      "Number of Classes: 4\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['Destination Port', 'NAT Source Port', 'Elapsed Time (sec)', 'pkts_received']\n",
    "\n",
    "# Get the selected features\n",
    "x_train_selected = X_train[selected_features]\n",
    "x_test_selected = X_test[selected_features]\n",
    "\n",
    "trainX = x_train_selected\n",
    "trainY = y_train\n",
    "\n",
    "testX = x_test_selected\n",
    "testY = y_test\n",
    "input_shape = trainX.shape[1]\n",
    "\n",
    "n_batch_size = 20\n",
    "\n",
    "n_steps_per_epoch = int(trainX.shape[0] / n_batch_size)\n",
    "\n",
    "n_test_steps = int(testX.shape[0] / n_batch_size)\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "num_classes = trainY.shape[1]\n",
    "\n",
    "print('Input Shape: ' + str(input_shape))\n",
    "print('Batch Size: ' + str(n_batch_size))\n",
    "print()\n",
    "print('Steps per Epoch: ' + str(n_steps_per_epoch))\n",
    "print()\n",
    "\n",
    "print('Test Steps: ' + str(n_test_steps))\n",
    "print()\n",
    "print('Number of Epochs: ' + str(n_epochs))\n",
    "print()\n",
    "print('Number of Classes: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10f44bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Destination Port  NAT Source Port  Elapsed Time (sec)  pkts_received\n",
      "count      45736.000000     45736.000000        45736.000000   45736.000000\n",
      "mean           0.122953         0.337317            0.006996       0.000215\n",
      "std            0.252164         0.337892            0.030400       0.007332\n",
      "min            0.000000         0.000000            0.000000       0.000000\n",
      "25%            0.000809         0.000000            0.000000       0.000000\n",
      "50%            0.006760         0.252102            0.002402       0.000003\n",
      "75%            0.006790         0.639113            0.002864       0.000012\n",
      "max            0.999527         1.000000            1.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "print(trainX.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b0dae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(input_shape,)))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a75486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 20)                100       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 84        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 604 (2.36 KB)\n",
      "Trainable params: 604 (2.36 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c561ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2286/2286 [==============================] - 1s 513us/step - loss: 0.2301 - accuracy: 0.9354\n",
      "Epoch 2/100\n",
      "2286/2286 [==============================] - 1s 496us/step - loss: 0.0986 - accuracy: 0.9752\n",
      "Epoch 3/100\n",
      "2286/2286 [==============================] - 1s 567us/step - loss: 0.0796 - accuracy: 0.9775\n",
      "Epoch 4/100\n",
      "2286/2286 [==============================] - 1s 583us/step - loss: 0.0595 - accuracy: 0.9818\n",
      "Epoch 5/100\n",
      "2286/2286 [==============================] - 1s 557us/step - loss: 0.0443 - accuracy: 0.9885\n",
      "Epoch 6/100\n",
      "2286/2286 [==============================] - 2s 720us/step - loss: 0.0358 - accuracy: 0.9936\n",
      "Epoch 7/100\n",
      "2286/2286 [==============================] - 1s 648us/step - loss: 0.0307 - accuracy: 0.9946\n",
      "Epoch 8/100\n",
      "2286/2286 [==============================] - 1s 580us/step - loss: 0.0270 - accuracy: 0.9953\n",
      "Epoch 9/100\n",
      "2286/2286 [==============================] - 1s 570us/step - loss: 0.0244 - accuracy: 0.9960\n",
      "Epoch 10/100\n",
      "2286/2286 [==============================] - 1s 560us/step - loss: 0.0226 - accuracy: 0.9964\n",
      "Epoch 11/100\n",
      "2286/2286 [==============================] - 1s 555us/step - loss: 0.0210 - accuracy: 0.9966\n",
      "Epoch 12/100\n",
      "2286/2286 [==============================] - 1s 565us/step - loss: 0.0201 - accuracy: 0.9967\n",
      "Epoch 13/100\n",
      "2286/2286 [==============================] - 1s 652us/step - loss: 0.0194 - accuracy: 0.9968\n",
      "Epoch 14/100\n",
      "2286/2286 [==============================] - 1s 561us/step - loss: 0.0188 - accuracy: 0.9970\n",
      "Epoch 15/100\n",
      "2286/2286 [==============================] - 1s 543us/step - loss: 0.0187 - accuracy: 0.9969\n",
      "Epoch 16/100\n",
      "2286/2286 [==============================] - 1s 554us/step - loss: 0.0179 - accuracy: 0.9970\n",
      "Epoch 17/100\n",
      "2286/2286 [==============================] - 1s 556us/step - loss: 0.0181 - accuracy: 0.9970\n",
      "Epoch 18/100\n",
      "2286/2286 [==============================] - 2s 746us/step - loss: 0.0178 - accuracy: 0.9970\n",
      "Epoch 19/100\n",
      "2286/2286 [==============================] - 1s 570us/step - loss: 0.0179 - accuracy: 0.9969\n",
      "Epoch 20/100\n",
      "2286/2286 [==============================] - 1s 590us/step - loss: 0.0177 - accuracy: 0.9970\n",
      "Epoch 21/100\n",
      "2286/2286 [==============================] - 1s 566us/step - loss: 0.0176 - accuracy: 0.9970\n",
      "Epoch 22/100\n",
      "2286/2286 [==============================] - 1s 539us/step - loss: 0.0175 - accuracy: 0.9970\n",
      "Epoch 23/100\n",
      "2286/2286 [==============================] - 1s 542us/step - loss: 0.0173 - accuracy: 0.9971\n",
      "Epoch 24/100\n",
      "2286/2286 [==============================] - 1s 598us/step - loss: 0.0175 - accuracy: 0.9970\n",
      "Epoch 25/100\n",
      "2286/2286 [==============================] - 1s 563us/step - loss: 0.0174 - accuracy: 0.9971\n",
      "Epoch 26/100\n",
      "2286/2286 [==============================] - 1s 569us/step - loss: 0.0172 - accuracy: 0.9970\n",
      "Epoch 27/100\n",
      "2286/2286 [==============================] - 1s 603us/step - loss: 0.0171 - accuracy: 0.9971\n",
      "Epoch 28/100\n",
      "2286/2286 [==============================] - 1s 551us/step - loss: 0.0172 - accuracy: 0.9972\n",
      "Epoch 29/100\n",
      "2286/2286 [==============================] - 1s 588us/step - loss: 0.0171 - accuracy: 0.9971\n",
      "Epoch 30/100\n",
      "2286/2286 [==============================] - 2s 752us/step - loss: 0.0173 - accuracy: 0.9971\n",
      "Epoch 31/100\n",
      "2286/2286 [==============================] - 1s 554us/step - loss: 0.0167 - accuracy: 0.9971\n",
      "Epoch 32/100\n",
      "2286/2286 [==============================] - 1s 559us/step - loss: 0.0171 - accuracy: 0.9971\n",
      "Epoch 33/100\n",
      "2286/2286 [==============================] - 1s 566us/step - loss: 0.0172 - accuracy: 0.9970\n",
      "Epoch 34/100\n",
      "2286/2286 [==============================] - 1s 576us/step - loss: 0.0167 - accuracy: 0.9971\n",
      "Epoch 35/100\n",
      "2286/2286 [==============================] - 1s 636us/step - loss: 0.0166 - accuracy: 0.9972\n",
      "Epoch 36/100\n",
      "2286/2286 [==============================] - 1s 646us/step - loss: 0.0171 - accuracy: 0.9972\n",
      "Epoch 37/100\n",
      "2286/2286 [==============================] - 1s 615us/step - loss: 0.0162 - accuracy: 0.9973\n",
      "Epoch 38/100\n",
      "2286/2286 [==============================] - 1s 588us/step - loss: 0.0169 - accuracy: 0.9970\n",
      "Epoch 39/100\n",
      "2286/2286 [==============================] - 1s 553us/step - loss: 0.0165 - accuracy: 0.9972\n",
      "Epoch 40/100\n",
      "2286/2286 [==============================] - 1s 586us/step - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 41/100\n",
      "2286/2286 [==============================] - 2s 663us/step - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 42/100\n",
      "2286/2286 [==============================] - 2s 699us/step - loss: 0.0165 - accuracy: 0.9971\n",
      "Epoch 43/100\n",
      "2286/2286 [==============================] - 1s 647us/step - loss: 0.0159 - accuracy: 0.9972\n",
      "Epoch 44/100\n",
      "2286/2286 [==============================] - 1s 550us/step - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 45/100\n",
      "2286/2286 [==============================] - 1s 562us/step - loss: 0.0165 - accuracy: 0.9972\n",
      "Epoch 46/100\n",
      "2286/2286 [==============================] - 1s 578us/step - loss: 0.0160 - accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "2286/2286 [==============================] - 2s 714us/step - loss: 0.0163 - accuracy: 0.9972\n",
      "Epoch 48/100\n",
      "2286/2286 [==============================] - 1s 555us/step - loss: 0.0162 - accuracy: 0.9972\n",
      "Epoch 49/100\n",
      "2286/2286 [==============================] - 1s 534us/step - loss: 0.0162 - accuracy: 0.9972\n",
      "Epoch 50/100\n",
      "2286/2286 [==============================] - 1s 544us/step - loss: 0.0161 - accuracy: 0.9972\n",
      "Epoch 51/100\n",
      "2286/2286 [==============================] - 1s 557us/step - loss: 0.0157 - accuracy: 0.9973\n",
      "Epoch 52/100\n",
      "2286/2286 [==============================] - 1s 537us/step - loss: 0.0164 - accuracy: 0.9972\n",
      "Epoch 53/100\n",
      "2286/2286 [==============================] - 2s 704us/step - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 54/100\n",
      "2286/2286 [==============================] - 1s 591us/step - loss: 0.0161 - accuracy: 0.9972\n",
      "Epoch 55/100\n",
      "2286/2286 [==============================] - 1s 537us/step - loss: 0.0160 - accuracy: 0.9972\n",
      "Epoch 56/100\n",
      "2286/2286 [==============================] - 1s 532us/step - loss: 0.0161 - accuracy: 0.9971\n",
      "Epoch 57/100\n",
      "2286/2286 [==============================] - 1s 540us/step - loss: 0.0153 - accuracy: 0.9973\n",
      "Epoch 58/100\n",
      "2286/2286 [==============================] - 1s 536us/step - loss: 0.0161 - accuracy: 0.9971\n",
      "Epoch 59/100\n",
      "2286/2286 [==============================] - 1s 540us/step - loss: 0.0155 - accuracy: 0.9973\n",
      "Epoch 60/100\n",
      "2286/2286 [==============================] - 1s 536us/step - loss: 0.0158 - accuracy: 0.9972\n",
      "Epoch 61/100\n",
      "2286/2286 [==============================] - 1s 531us/step - loss: 0.0155 - accuracy: 0.9973\n",
      "Epoch 62/100\n",
      "2286/2286 [==============================] - 1s 544us/step - loss: 0.0160 - accuracy: 0.9971\n",
      "Epoch 63/100\n",
      "2286/2286 [==============================] - 1s 558us/step - loss: 0.0152 - accuracy: 0.9973\n",
      "Epoch 64/100\n",
      "2286/2286 [==============================] - 1s 533us/step - loss: 0.0158 - accuracy: 0.9972\n",
      "Epoch 65/100\n",
      "2286/2286 [==============================] - 1s 538us/step - loss: 0.0159 - accuracy: 0.9972\n",
      "Epoch 66/100\n",
      "2286/2286 [==============================] - 2s 829us/step - loss: 0.0152 - accuracy: 0.9973\n",
      "Epoch 67/100\n",
      "2286/2286 [==============================] - 1s 536us/step - loss: 0.0157 - accuracy: 0.9972\n",
      "Epoch 68/100\n",
      "2286/2286 [==============================] - 1s 533us/step - loss: 0.0159 - accuracy: 0.9972\n",
      "Epoch 69/100\n",
      "2286/2286 [==============================] - 1s 565us/step - loss: 0.0151 - accuracy: 0.9974\n",
      "Epoch 70/100\n",
      "2286/2286 [==============================] - 1s 543us/step - loss: 0.0159 - accuracy: 0.9972\n",
      "Epoch 71/100\n",
      "2286/2286 [==============================] - 1s 589us/step - loss: 0.0157 - accuracy: 0.9972\n",
      "Epoch 72/100\n",
      "2286/2286 [==============================] - 2s 713us/step - loss: 0.0156 - accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "2286/2286 [==============================] - 1s 614us/step - loss: 0.0148 - accuracy: 0.9974\n",
      "Epoch 74/100\n",
      "2286/2286 [==============================] - 1s 626us/step - loss: 0.0156 - accuracy: 0.9972\n",
      "Epoch 75/100\n",
      "2286/2286 [==============================] - 1s 602us/step - loss: 0.0148 - accuracy: 0.9973\n",
      "Epoch 76/100\n",
      "2286/2286 [==============================] - 1s 588us/step - loss: 0.0155 - accuracy: 0.9974\n",
      "Epoch 77/100\n",
      "2286/2286 [==============================] - 2s 807us/step - loss: 0.0155 - accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "2286/2286 [==============================] - 1s 619us/step - loss: 0.0150 - accuracy: 0.9974\n",
      "Epoch 79/100\n",
      "2286/2286 [==============================] - 1s 629us/step - loss: 0.0158 - accuracy: 0.9971\n",
      "Epoch 80/100\n",
      "2286/2286 [==============================] - 1s 636us/step - loss: 0.0150 - accuracy: 0.9974\n",
      "Epoch 81/100\n",
      "2286/2286 [==============================] - 2s 743us/step - loss: 0.0153 - accuracy: 0.9972\n",
      "Epoch 82/100\n",
      "2286/2286 [==============================] - 1s 551us/step - loss: 0.0151 - accuracy: 0.9973\n",
      "Epoch 83/100\n",
      "2286/2286 [==============================] - 1s 625us/step - loss: 0.0146 - accuracy: 0.9974\n",
      "Epoch 84/100\n",
      "2286/2286 [==============================] - 1s 591us/step - loss: 0.0157 - accuracy: 0.9973\n",
      "Epoch 85/100\n",
      "2286/2286 [==============================] - 1s 552us/step - loss: 0.0152 - accuracy: 0.9974\n",
      "Epoch 86/100\n",
      "2286/2286 [==============================] - 1s 593us/step - loss: 0.0147 - accuracy: 0.9974\n",
      "Epoch 87/100\n",
      "2286/2286 [==============================] - 1s 562us/step - loss: 0.0154 - accuracy: 0.9972\n",
      "Epoch 88/100\n",
      "2286/2286 [==============================] - 2s 697us/step - loss: 0.0145 - accuracy: 0.9974\n",
      "Epoch 89/100\n",
      "2286/2286 [==============================] - 2s 664us/step - loss: 0.0155 - accuracy: 0.9973\n",
      "Epoch 90/100\n",
      "2286/2286 [==============================] - 1s 598us/step - loss: 0.0148 - accuracy: 0.9974\n",
      "Epoch 91/100\n",
      "2286/2286 [==============================] - 1s 568us/step - loss: 0.0152 - accuracy: 0.9974\n",
      "Epoch 92/100\n",
      "2286/2286 [==============================] - 1s 559us/step - loss: 0.0148 - accuracy: 0.9974\n",
      "Epoch 93/100\n",
      "2286/2286 [==============================] - 2s 675us/step - loss: 0.0152 - accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "2286/2286 [==============================] - 1s 551us/step - loss: 0.0151 - accuracy: 0.9974\n",
      "Epoch 95/100\n",
      "2286/2286 [==============================] - 1s 557us/step - loss: 0.0147 - accuracy: 0.9974\n",
      "Epoch 96/100\n",
      "2286/2286 [==============================] - 1s 573us/step - loss: 0.0144 - accuracy: 0.9975\n",
      "Epoch 97/100\n",
      "2286/2286 [==============================] - 2s 662us/step - loss: 0.0154 - accuracy: 0.9973\n",
      "Epoch 98/100\n",
      "2286/2286 [==============================] - 1s 571us/step - loss: 0.0151 - accuracy: 0.9974\n",
      "Epoch 99/100\n",
      "2286/2286 [==============================] - 1s 593us/step - loss: 0.0146 - accuracy: 0.9974\n",
      "Epoch 100/100\n",
      "2286/2286 [==============================] - 2s 754us/step - loss: 0.0151 - accuracy: 0.9974\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train_selected,\n",
    "                    y_train,\n",
    "                    steps_per_epoch=n_steps_per_epoch,\n",
    "                    epochs=n_epochs,\n",
    "                    batch_size=n_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "475e5aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 399us/step\n",
      "Accuracy: 0.9978135385691796\n",
      "Precision: 0.7470183090283516\n",
      "Recall: 0.7480953293692627\n",
      "F1 Score: 0.7475560176212065\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(x_test_selected)\n",
    "y_pred_classes_test = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_back_test = encoder.inverse_transform(np.eye(num_classes)[y_pred_classes_test])\n",
    "\n",
    "\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "y_test_back = encoder.inverse_transform(np.eye(num_classes)[y_test_classes])\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy_dnn_sel = accuracy_score(y_test_back, y_pred_back)\n",
    "precision_dnn_sel = precision_score(y_test_back, y_pred_back, average='macro')\n",
    "recall_dnn_sel = recall_score(y_test_back, y_pred_back, average='macro')\n",
    "f1_dnn_sel = f1_score(y_test_back, y_pred_back, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy_dnn_sel)\n",
    "print(\"Precision:\", precision_dnn_sel)\n",
    "print(\"Recall:\", recall_dnn_sel)\n",
    "print(\"F1 Score:\", f1_dnn_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0f3aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the metric names\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Define the average metric values for selected features\n",
    "selected_metrics = [accuracy_dnn_sel, precision_dnn_sel, recall_dnn_sel, f1_dnn_sel]\n",
    "\n",
    "# Define the average metric values for all features\n",
    "all_metrics = [accuracy_dnn_all, precision_dnn_all, recall_dnn_all, f1_dnn_all]\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set the positions of the bars on the x-axis with increased gaps\n",
    "r1 = np.arange(len(metric_names)) * 2\n",
    "r2 = [x + bar_width + 0.1 for x in r1]\n",
    "\n",
    "# Calculate the center position for metric names\n",
    "metric_names_center = [(r1[i] + r2[i]) / 2 for i in range(len(r1))]\n",
    "\n",
    "# Create the bar plot with reversed order and modified colors\n",
    "plt.bar(r1, all_metrics, width=bar_width,alpha=0.95, label='All Features')\n",
    "plt.bar(r2, selected_metrics, width=bar_width, alpha=0.95,label='Selected Features')\n",
    "\n",
    "# Add labels, title, and x-axis tick labels\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Average Value')\n",
    "plt.title('DNN')\n",
    "plt.xticks(metric_names_center, metric_names)\n",
    "\n",
    "# Set the y-axis range\n",
    "plt.ylim(0.5, 1.02)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e9225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
